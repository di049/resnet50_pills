{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d359a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torchvision.transforms.v2 import RandomHorizontalFlip, RandomVerticalFlip, RandomRotation\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4558c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1233c54",
   "metadata": {},
   "source": [
    "# Этап 1. Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f171f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/ogyeiv2/train'\n",
    "test_path = 'data/ogyeiv2/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5049450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(train_path)\n",
    "test_dataset = ImageFolder(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45cf6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformDataset(Dataset):\n",
    "  def __init__(self, dataset, transforms):\n",
    "    super(TransformDataset, self).__init__()\n",
    "    self.dataset = dataset\n",
    "    self.transforms = transforms\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    x, y = self.dataset[idx]\n",
    "    return self.transforms(x), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c972c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    RandomHorizontalFlip(p=0.2),\n",
    "    RandomVerticalFlip(p=0.2),\n",
    "    RandomRotation([-5, 5], fill=255.),\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "test_transforms = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize((0.5), (0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae398f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TransformDataset(train_dataset, train_transforms)\n",
    "test= TransformDataset(test_dataset, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "178a0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(test,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d61254c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train-датасета:  2352\n",
      "Размер test-датасета:  504\n",
      "Кол-во классов:  84\n"
     ]
    }
   ],
   "source": [
    "print('Размер train-датасета: ', len(train_dataset))\n",
    "print('Размер test-датасета: ', len(test_dataset))\n",
    "print('Кол-во классов: ', len(train_dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08c772",
   "metadata": {},
   "source": [
    "# Этап 2. Объявление модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ffb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights='IMAGENET1K_V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Меняем последний слой нейросети для предсказания 84 классов\n",
    "model.fc = nn.Linear(in_features=2048, out_features=84, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "669b59ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=84, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cef8cf",
   "metadata": {},
   "source": [
    "# Этап 3. Обучение или дообучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2167e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fd00b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for batch_index, data in enumerate(train_loader):\n",
    "        # Извлечение батча\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Обнуление градиентов\n",
    "        optimizer.zero_grad()\n",
    "        # Прямое распространение\n",
    "        outputs = model(inputs)\n",
    "        # Подсчёт ошибки\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Обратное распространение\n",
    "        loss.backward()\n",
    "        # Обновление весов\n",
    "        optimizer.step()\n",
    "\n",
    "        # Суммирование ошибки за последние 100 батчей\n",
    "        running_loss += loss.item()\n",
    "        if batch_index == 73:\n",
    "            last_loss = running_loss / 73. # средняя ошибка за 100 батчей\n",
    "            print(f'Эпоха: {epoch_index}, батч: {batch_index}, ошибка {last_loss}')\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacbc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0\n",
      "Эпоха: 0, батч: 73, ошибка 0.09332129493840549\n",
      "В конце эпохи ошибка train 0.09332129493840549, ошибка val 29.38132667541504\n",
      "Эпоха 1\n",
      "Эпоха: 1, батч: 73, ошибка 0.06334399998392144\n",
      "В конце эпохи ошибка train 0.06334399998392144, ошибка val 1.319373369216919\n",
      "Эпоха 2\n",
      "Эпоха: 2, батч: 73, ошибка 0.09897583220409203\n",
      "В конце эпохи ошибка train 0.09897583220409203, ошибка val 17.412233352661133\n",
      "Эпоха 3\n",
      "Эпоха: 3, батч: 73, ошибка 0.05775509235666019\n",
      "В конце эпохи ошибка train 0.05775509235666019, ошибка val 24.429367065429688\n",
      "Эпоха 4\n",
      "Эпоха: 4, батч: 73, ошибка 0.08074471872134058\n",
      "В конце эпохи ошибка train 0.08074471872134058, ошибка val 48.580909729003906\n",
      "Эпоха 5\n",
      "Эпоха: 5, батч: 73, ошибка 0.04489767932562693\n",
      "В конце эпохи ошибка train 0.04489767932562693, ошибка val 1.3325735330581665\n",
      "Эпоха 6\n",
      "Эпоха: 6, батч: 73, ошибка 0.07298398970734736\n",
      "В конце эпохи ошибка train 0.07298398970734736, ошибка val 0.242804616689682\n",
      "Эпоха 7\n",
      "Эпоха: 7, батч: 73, ошибка 0.06588137804288162\n",
      "В конце эпохи ошибка train 0.06588137804288162, ошибка val 2.256290912628174\n",
      "Эпоха 8\n",
      "Эпоха: 8, батч: 73, ошибка 0.0255688262197559\n",
      "В конце эпохи ошибка train 0.0255688262197559, ошибка val 0.5646288394927979\n",
      "Эпоха 9\n",
      "Эпоха: 9, батч: 73, ошибка 0.06520349358221235\n",
      "В конце эпохи ошибка train 0.06520349358221235, ошибка val 1.2650129795074463\n",
      "Эпоха 10\n",
      "Эпоха: 10, батч: 73, ошибка 0.04990361206080407\n",
      "В конце эпохи ошибка train 0.04990361206080407, ошибка val 0.360323965549469\n",
      "Эпоха 11\n",
      "Эпоха: 11, батч: 73, ошибка 0.07750428438645927\n",
      "В конце эпохи ошибка train 0.07750428438645927, ошибка val 0.8175643682479858\n",
      "Эпоха 12\n",
      "Эпоха: 12, батч: 73, ошибка 0.04249828932360325\n",
      "В конце эпохи ошибка train 0.04249828932360325, ошибка val 2.722031831741333\n",
      "Эпоха 13\n",
      "Эпоха: 13, батч: 73, ошибка 0.025836013172982796\n",
      "В конце эпохи ошибка train 0.025836013172982796, ошибка val 7.041386127471924\n",
      "Эпоха 14\n",
      "Эпоха: 14, батч: 73, ошибка 0.014383259669507611\n",
      "В конце эпохи ошибка train 0.014383259669507611, ошибка val 0.08778637647628784\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "best_vloss = 1e5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Эпоха {epoch}')\n",
    "\n",
    "    # Перевод модели в режим обучения\n",
    "    model.train(True)\n",
    "    # Эпоха обучения\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "    # Перевод модели в режим валидации\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    # Валидация\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(test_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = criterion(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "\n",
    "    # Сохранение лучшей модели\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'meds_classifier_{epoch}.pt'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print(f'В конце эпохи ошибка train {avg_loss}, ошибка val {avg_vloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249300c",
   "metadata": {},
   "source": [
    "# Этап 4. Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b6ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()\n",
    "model.fc = nn.Linear(in_features=2048, out_features=84, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a36cd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=84, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('meds_classifier_14.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f17e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                 acc_long_600_mg       0.86      1.00      0.92         6\n",
      "               advil_ultra_forte       1.00      1.00      1.00         6\n",
      "                   akineton_2_mg       1.00      1.00      1.00         6\n",
      "      algoflex_forte_dolo_400_mg       1.00      1.00      1.00         6\n",
      "           algoflex_rapid_400_mg       1.00      1.00      1.00         6\n",
      "                algopyrin_500_mg       1.00      1.00      1.00         6\n",
      "             ambroxol_egis_30_mg       1.00      1.00      1.00         6\n",
      "                  apranax_550_mg       1.00      1.00      1.00         6\n",
      "            aspirin_ultra_500_mg       1.00      1.00      1.00         6\n",
      "                    atoris_20_mg       1.00      1.00      1.00         6\n",
      "         atorvastatin_teva_20_mg       1.00      1.00      1.00         6\n",
      "                   betaloc_50_mg       1.00      1.00      1.00         6\n",
      "                        bila_git       1.00      1.00      1.00         6\n",
      "           c_vitamin_teva_500_mg       1.00      1.00      1.00         6\n",
      "                       calci_kid       1.00      0.83      0.91         6\n",
      "                  cataflam_50_mg       1.00      0.83      0.91         6\n",
      "             cataflam_dolo_25_mg       1.00      0.83      0.91         6\n",
      "                 cetirizin_10_mg       1.00      1.00      1.00         6\n",
      "                         cold_fx       1.00      1.00      1.00         6\n",
      "                         coldrex       1.00      1.00      1.00         6\n",
      "                    concor_10_mg       1.00      1.00      1.00         6\n",
      "                     concor_5_mg       1.00      1.00      1.00         6\n",
      "               condrosulf_800_mg       1.00      1.00      1.00         6\n",
      "                 controloc_20_mg       1.00      1.00      1.00         6\n",
      "covercard_plus_10_mg_2_5_mg_5_mg       1.00      1.00      1.00         6\n",
      "                    coverex_4_mg       1.00      1.00      1.00         6\n",
      "           diclopram_75-mg_20-mg       1.00      0.67      0.80         6\n",
      "              dorithricin_mentol       1.00      1.00      1.00         6\n",
      "                  dulsevia_60_mg       1.00      1.00      1.00         6\n",
      "                  enterol_250_mg       1.00      0.83      0.91         6\n",
      "      favipiravir_meditop_200_mg       1.00      1.00      1.00         6\n",
      "                   ibumax_400_mg       1.00      1.00      1.00         6\n",
      "               jutavit_c_vitamin       0.75      1.00      0.86         6\n",
      "                    jutavit_cink       1.00      0.67      0.80         6\n",
      "          kalcium_magnezium_cink       1.00      0.33      0.50         6\n",
      "                        kalium_r       1.00      1.00      1.00         6\n",
      "            koleszterin_kontroll       1.00      1.00      1.00         6\n",
      "                        lactamed       1.00      1.00      1.00         6\n",
      "                     lactiv_plus       0.86      1.00      0.92         6\n",
      "                   laresin_10_mg       1.00      1.00      1.00         6\n",
      "            letrox_50_mikrogramm       1.00      1.00      1.00         6\n",
      "                  lordestin_5_mg       1.00      1.00      1.00         6\n",
      "          merckformin_xr_1000_mg       0.60      1.00      0.75         6\n",
      "                        meridian       1.00      1.00      1.00         6\n",
      "                metothyrin_10_mg       1.00      1.00      1.00         6\n",
      "       mezym_forte_10_000_egyseg       1.00      1.00      1.00         6\n",
      "                        milgamma       1.00      1.00      1.00         6\n",
      "                  milurit_300_mg       1.00      1.00      1.00         6\n",
      "                 naprosyn_250_mg       1.00      1.00      1.00         6\n",
      "          narva_sr_1_5_mg_retard       0.75      1.00      0.86         6\n",
      "       naturland_d_vitamin_forte       1.00      1.00      1.00         6\n",
      "           nebivolol_sandoz_5_mg       1.00      1.00      1.00         6\n",
      "                      neo_citran       1.00      1.00      1.00         6\n",
      "neo_ferro_folgamma_114_mg_0_8_mg       0.86      1.00      0.92         6\n",
      "                   nolpaza_20_mg       1.00      1.00      1.00         6\n",
      "                normodipine_5_mg       1.00      1.00      1.00         6\n",
      "                     novo_c_plus       1.00      1.00      1.00         6\n",
      "            nurofen_forte_400_mg       1.00      1.00      1.00         6\n",
      "                         ocutein       1.00      1.00      1.00         6\n",
      "                   olicard_60_mg       1.00      1.00      1.00         6\n",
      "                  quamatel_40_mg       0.86      1.00      0.92         6\n",
      "                 rubophen_500_mg       1.00      1.00      1.00         6\n",
      "           salazopyrin_en_500_mg       1.00      1.00      1.00         6\n",
      "                      sedatif_pc       1.00      1.00      1.00         6\n",
      "               semicillin_500_mg       1.00      1.00      1.00         6\n",
      "                     sicor_10_mg       0.67      1.00      0.80         6\n",
      "                  sinupret_forte       1.00      1.00      1.00         6\n",
      "                strepfen_8_75_mg       1.00      1.00      1.00         6\n",
      "                       strepsils       1.00      1.00      1.00         6\n",
      "            teva_ambrobene_30_mg       1.00      1.00      1.00         6\n",
      "            teva_enterobene_2_mg       1.00      1.00      1.00         6\n",
      "               theospirex_150_mg       1.00      1.00      1.00         6\n",
      "             tricovel_tricoage45       1.00      1.00      1.00         6\n",
      "                    tritace_5_mg       1.00      0.50      0.67         6\n",
      "          tritace_hct_5_mg_25_mg       1.00      1.00      1.00         6\n",
      "                         urotrin       1.00      1.00      1.00         6\n",
      "                         urzinol       1.00      1.00      1.00         6\n",
      "                  valeriana_teva       1.00      1.00      1.00         6\n",
      "                verospiron_25_mg       1.00      1.00      1.00         6\n",
      "                          vita_c       1.00      1.00      1.00         6\n",
      "    vitamin_d3_fresenius_1000_ne       1.00      1.00      1.00         6\n",
      "       voltaren_dolo_rapid_25_mg       1.00      1.00      1.00         6\n",
      "                     xeter_20_mg       1.00      1.00      1.00         6\n",
      "                     zadex_60_mg       1.00      1.00      1.00         6\n",
      "\n",
      "                        accuracy                           0.97       504\n",
      "                       macro avg       0.98      0.97      0.97       504\n",
      "                    weighted avg       0.98      0.97      0.97       504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_predicted = []\n",
    "labels_true = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1) # argmax по всем примерам\n",
    "        labels_predicted.extend(predicted.cpu().numpy())\n",
    "        labels_true.extend(labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(labels_true, labels_predicted, target_names=test_dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d7c1ac",
   "metadata": {},
   "source": [
    "# Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf02f0",
   "metadata": {},
   "source": [
    "* На каких 5 классах модель ошибается чаще всего?\n",
    "\n",
    "    Чаще всего модель ошибается на классах kalcium_magnezium_cink, tritace_5_mg, merckformin_xr_1000_mg, diclopram_75-mg_20-mg, jutavit_cink, sicor_10_mg - у этих классов самое низкое значение F1-score.\n",
    "\n",
    "* Почему модель может ошибаться на этих классах?\n",
    "\n",
    "    Модель может ошибаться на этих классах из-за схожести внешнего вида некоторых классов таблеток, например:\n",
    "    kalcium_magnezium_cink схожи с merckformin_xr_1000_mg\n",
    "    sicor_10_mg схожи с tritace_5_mg\n",
    "    narva_sr_1_5_mg_retard схожи с jutavit_cink\n",
    "    jutavit_c_vitamin схожи с diclopram_75-mg_20-mg.\n",
    "\n",
    "* На каких классах модель не совершает ошибок?\n",
    "\n",
    "    Модель не совершает ошибок на большинстве классов датасета (68 безошибочных классов из 84).\n",
    "\n",
    "* Почему эти классы модель распознаёт безошибочно?\n",
    "\n",
    "    Эти классы имеют больше отличительных черт (цвет, форма).\n",
    "\n",
    "* Как можно улучшить точность классификатора?\n",
    "\n",
    "    Для улучшения точности можно попробовать другие аугментации, либо не использовать их совсем, так как изображения в обучающем датасете практически не отличаются от изображений в валидационном (одна таблетка на нейтральном фоне, без посторонних предметов и другого шума).\n",
    "\n",
    "* Как ещё можно проанализировать результаты и ошибки модели?\n",
    "\n",
    "    Можно изучить изображения, полученные в результате аугментации и проанализировать, с какими именно классами модель путает классы с низким F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c7274",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
